{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/tp/01_aprendizaje_supervisado/tp01-enunciado.ipynb)\n",
    "\n",
    "# Trabajo Práctico -  Aprendizaje supervisado\n",
    "### Clasificación de expresiones genómicas\n",
    "\n",
    "<span style=\"color: red;\">**Fecha de entrega: Jueves 01 de mayo del 2025 - hasta las 17:00hs.**\n",
    " \n",
    "<span style=\"color: red;\">**Fecha de entrega intermedia: Jueves 17 de Abril del 2025 - hasta las 17:00hs.**\n",
    "</span>\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En el mundo actual, distintas disciplinas científicas empiezan, cada vez más, a interactuar con el fin de potenciar sus descubrimientos. En este caso dos grupos de investigación de [CONICET](https://www.conicet.gov.ar/) se embarcan en la combinación entre biología y informática para abordar la detección temprana y el pronóstico preciso de enfermedades como el cáncer. Este proyecto combina las tecnologías de secuenciación de nueva generación ([_NGS_](https://es.wikipedia.org/wiki/Secuenciaci%C3%B3n_paralela_masiva), por sus siglas en inglés) con la potencia de la inteligencia artificial. El enfoque se centra en un dataset único que abarca mediciones de [_ARN_](https://es.wikipedia.org/wiki/ARN_mensajero) de 200 [_genes_](https://es.wikipedia.org/wiki/Gen), recopiladas de pacientes con lesiones [_pre-tumorales_](https://en.wikipedia.org/wiki/Hyperplasia). Este conjunto de datos se convierte en una valiosa fuente de información para entender cómo las células en estado de hiperplasia pueden evolucionar hacia [_tumores malignos_](https://en.wikipedia.org/wiki/Neoplasm), una transformación que ha desconcertado a la ciencia durante décadas.\n",
    "\n",
    "La hiperplasia, es un fenómeno en el que las células experimentan un crecimiento anormal y descontrolado, es un punto de partida crucial en nuestro análisis. ¿Cómo y por qué algunas células que experimentan hiperplasia se convierten en células cancerosas, mientras que otras no? Esta pregunta es el corazón de nuestra investigación. Para responderla se realizo un estudio donde se obtuvieron muestras de distintos tipos de hiperplasias de pacientes con antecedentes familiares y lesiones pre tumorales. Este grupo de pacientes, o cohorte, fue monitoreado periodicamente durante los siguientes 5 años buscando indicios de neoplasias o nuevas hiperplasias más agresivas. Con las muestras obtenidas en este estudio se realizo un [_biobanco_](https://en.wikipedia.org/wiki/Biobank) con las mediciones que habitualmente se hacen en la construccion de este tipo de [_plataformas_](https://xena.ucsc.edu/). Cada muestra fue etiquetada como **_buen pronostico_**, si no hubo indicios de nuevas hiperplasias o similares; contrariamente se etiquetaron como de **_mal pronostico_** si hubo una recaida.\n",
    "\n",
    "Este trabajo se concentra en un panel de genes, especificamente en la expresion de 200 genes que se creen tienen un papel crucial en la transformacion tumoral y su etiqueta correspondiente.\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán un archivo `.csv` en donde se almacenan:\n",
    "  - una matriz de datos `X` de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$.\n",
    "  - una columna llamada `target` que representa un vector de $500$ posiciones con dos posibles valores: `True` (ó 1, es decir, tiene buen pronostico) y `False` (ó 0, tiene mal pronostico).\n",
    "\n",
    "Los datos están en esta [carpeta](https://github.com/aprendizaje-automatico-dc-uba-ar/material/tree/main/tp/01_aprendizaje_supervisado/datos).\n",
    "\n",
    "Por otra parte, tendrán disponibles un conjunto de instancias sin etiquetas, que utilizaremos para comprobar la calidad de sus resultados (ver Ejercicio 5). \n",
    "\n",
    "**Recomendamos fuertemente leer primero todo el enunciado del trabajo antes de empezar a trabajar sobre el problema propuesto.**\n",
    "\n",
    "---\n",
    "\n",
    "### Sobre el informe\n",
    "\n",
    "Para este trabajo deberán entregar, además del código de las pruebas y experimentos que realicen, un informe en el que deberan seleccionar, para cada apartado, sus resultados acompañado de un texto que explique, reflexione, justifique y conluya dicho contenido. \n",
    "\n",
    "Cada ejercicio indica el largo máximo del texto que se puede incluir. Los gráficos no están contados en dicho espacio. \n",
    "Cada gráfico incluido debe contar con:\n",
    "  \n",
    "  - nombres de los ejes,\n",
    "  - título,\n",
    "  - leyenda autocontenida,\n",
    "  - debe ser referenciado desde el texto, ya que su inclusión se da porque aporta a la discusión del trabajo.\n",
    "\n",
    "**El informe no puede superar un máximo de 8 carillas (contando gráficos) o 4 hojas más carátula.** Tamaño de la letra: estandár de latex (10pt). No se corregirán trabajos que no cumplan con esta consigna.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold,RandomizedSearchCV,ParameterGrid,cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, auc, roc_auc_score,average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 \n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. \n",
    "\n",
    "Evaluar y justificar cómo separarán sus datos para desarrollo y para evaluación. ¿Qué consideraciones tuvieron en cuenta para realizar esta división?\n",
    "\n",
    "**Importante**: en este punto no está permitido dividir la base de datos utilizando la función `train_test_split` de sklearn. Deben decidir e implementar la separación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 201)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data.csv\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c1 = df[df['target'] == 1]\n",
    "df_c2 = df[df['target'] == 0]\n",
    "\n",
    "# Mezclar aleatoriamente\n",
    "df_c1 = df_c1.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_c2 = df_c2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Tamaño total del dataset\n",
    "n_total = len(df)\n",
    "n_eval = int(0.2 * n_total)  # 20% para evaluación\n",
    "\n",
    "# Cantidades por clase para evaluación\n",
    "n_eval_c1 = int(0.2 * len(df_c1))  # 30\n",
    "n_eval_c2 = n_eval - n_eval_c1     # 70\n",
    "\n",
    "# Separar evaluación\n",
    "df_eval_c1 = df_c1.iloc[:n_eval_c1]\n",
    "df_eval_c2 = df_c2.iloc[:n_eval_c2]\n",
    "\n",
    "# Lo que queda es desarrollo\n",
    "df_dev_c1 = df_c1.iloc[n_eval_c1:]\n",
    "df_dev_c2 = df_c2.iloc[n_eval_c2:]\n",
    "\n",
    "# Combinar y mezclar\n",
    "df_eval = pd.concat([df_eval_c1, df_eval_c2]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_dev = pd.concat([df_dev_c1, df_dev_c2]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_dev = df_dev.drop(columns=[\"target\"])\n",
    "y_dev = df_dev[\"target\"]\n",
    "X_eval=df_eval.drop(columns=[\"target\"])\n",
    "y_eval=df_eval[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo **árbol de decisión**. Además, obtener una **estimación realista de la performance** de los mismos.\n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model=DecisionTreeClassifier(max_depth=3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Estimar la performance del modelo utilizando _K-fold cross validation_ con `K=5`, con las métricas _Accuracy_, _Area Under the Precision-Recall Curve (AUPRC)_, y _Area Under the Receiver Operating Characteristic Curve (AUCROC)_. \n",
    "\n",
    "   En esta oportunidad se va a pedir además de calcular las métricas para cada fold por separado y su promedio, que hagan el cálculo del score global (como vimos en clase), sólo para los folds de validación.\n",
    "   \n",
    "   Reportar el resultado en una tabla similar a:\n",
    "\n",
    "      <table>\n",
    "      <thead>\n",
    "      <tr>\n",
    "      <th align=\"center\">Permutación</th>\n",
    "      <th>Accuracy (training)</th>\n",
    "      <th>Accuracy (validación)</th>\n",
    "      <th>AUPRC (training)</th>\n",
    "      <th>AUPRC (validación)</th>\n",
    "      <th>AUC ROC (training)</th>\n",
    "      <th>AUC ROC (validación)</th>\n",
    "      </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "      <tr>\n",
    "      <td align=\"center\">1</td>\n",
    "      <td>0.83125</td>\n",
    "      <td>0.675</td>\n",
    "      <td>0.68118773</td>\n",
    "      <td>0.34724893</td>\n",
    "      <td>0.82934215</td>\n",
    "      <td>0.57738095</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">2</td>\n",
    "      <td>0.784375</td>\n",
    "      <td>0.6</td>\n",
    "      <td>0.65482599</td>\n",
    "      <td>0.37581619</td>\n",
    "      <td>0.83172299</td>\n",
    "      <td> 0.62165179</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">3</td>\n",
    "      <td>0.790625</td>\n",
    "      <td>0.7375</td>\n",
    "      <td>0.66016275</td>\n",
    "      <td>0.43671292</td>\n",
    "      <td>0.83026675</td>\n",
    "      <td>0.6499256</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">4</td>\n",
    "      <td>0.853125</td>\n",
    "      <td>0.6125</td>\n",
    "      <td>0.74582953</td>\n",
    "      <td>0.27594626</td>\n",
    "      <td>0.83239332</td>\n",
    "      <td>0.4375</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">5</td>\n",
    "      <td>0.784375</td>\n",
    "      <td>0.7</td>\n",
    "      <td>0.65221835</td>\n",
    "      <td>0.40623895</td>\n",
    "      <td>0.81794085</td>\n",
    "      <td>0.64763636</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "      <td align=\"center\">Promedios</td>\n",
    "      <td>0.8087500000000001</td>\n",
    "      <td>0.665</td>\n",
    "      <td>0.6788448710972432</td>\n",
    "      <td>0.3683926507628855</td>\n",
    "      <td>0.82833321148096</td>\n",
    "      <td>0.5868189393939394</td>\n",
    "      </tr>\n",
    "      <td align=\"center\">Global</td>\n",
    "      <td>(NO) </td>\n",
    "      <td>0.665</td>\n",
    "      <td>(NO) </td>\n",
    "      <td>0.3652341593248588</td>\n",
    "      <td>(NO) </td>\n",
    "      <td>0.6109185698628515</td>\n",
    "      </tr>\n",
    "      </tbody>\n",
    "      </table>    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El train_accuracy es [0.83125  0.784375 0.790625 0.853125 0.784375] con promedio 0.8087500000000001 y el test_accuracy es [0.675  0.6    0.7375 0.6125 0.7   ] con promedio 0.665\n",
      "El train_auprc es [0.68118773 0.65482599 0.66016275 0.74582953 0.65221835] con promedio 0.6788448710972432 y el test_auprc es [0.34724893 0.37581619 0.43671292 0.27594626 0.40623895] con promedio 0.3683926507628855\n",
      "El train_aucroc es [0.82934215 0.83172299 0.83026675 0.83239332 0.81794085] con promedio 0.82833321148096 y el test_accuracy es [0.57738095 0.62165179 0.6499256  0.4375     0.64763636] con promedio 0.5868189393939394\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluación con múltiples métricas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'auprc': 'average_precision',\n",
    "    'aucroc': 'roc_auc'\n",
    "}\n",
    "scores = cross_validate(\n",
    "    tree_model,\n",
    "    X_dev,\n",
    "    y_dev,\n",
    "    cv=skf,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "train_accuracy=scores['train_accuracy']\n",
    "test_accuracy=scores[\"test_accuracy\"]\n",
    "print(f\"El train_accuracy es {train_accuracy} con promedio {train_accuracy.mean()} y el test_accuracy es {test_accuracy} con promedio {test_accuracy.mean()}\") \n",
    "train_auprc=scores['train_auprc']\n",
    "test_auprc=scores['test_auprc']\n",
    "print(f\"El train_auprc es {train_auprc} con promedio {train_auprc.mean()} y el test_auprc es {test_auprc} con promedio {test_auprc.mean()}\") \n",
    "train_aucroc=scores['train_aucroc']\n",
    "test_aucroc=scores[\"test_aucroc\"]\n",
    "print(f\"El train_aucroc es {train_aucroc} con promedio {train_aucroc.mean()} y el test_accuracy es {test_aucroc} con promedio {test_aucroc.mean()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy global para los datos de validacion es 0.665\n",
      "El AUPRC global para los datos de validacion es 0.3652341593248588\n",
      "El AUROC global para los datos de validacion es 0.6109185698628515\n"
     ]
    }
   ],
   "source": [
    "#Ahora calculamos los scores globales sobre los conjuntos de validacion\n",
    "y_pred = cross_val_predict(tree_model, X_dev, y_dev, cv=skf)\n",
    "print(f\"El accuracy global para los datos de validacion es {accuracy_score(y_dev,y_pred)}\")\n",
    "y_proba = cross_val_predict(tree_model, X_dev, y_dev, cv=skf, method='predict_proba')\n",
    "y_scores=y_proba[:,1]\n",
    "print(f\"El AUPRC global para los datos de validacion es {average_precision_score(y_dev,y_scores)}\")\n",
    "print(f\"El AUROC global para los datos de validacion es {roc_auc_score(y_dev,y_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*INCISO 3*\n",
    "   **Importante**: de acá en más sólamente utilizaremos el score promedio cuando hagamos _K-fold cross-validation_.\n",
    "1. Explorar las siguientes combinaciones de parámetros para  árboles de decisión (siguiendo con $k-fold$ con $k=5$) utilizando [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) de _scikit learn_. No está permitido utilizar `GridSearchCV` en este ejercicio.\n",
    "\n",
    "   <table>\n",
    "   <thead>\n",
    "   <tr>\n",
    "   <th align=\"center\">Altura máxima</th>\n",
    "   <th align=\"center\">Criterio de corte</th>\n",
    "   <th>Accuracy (training)</th>\n",
    "   <th>Accuracy (validación)</th>\n",
    "   </tr>\n",
    "   </thead>\n",
    "   <tbody><tr>\n",
    "   <td align=\"center\">3</td>\n",
    "   <td align=\"center\">Gini</td>\n",
    "   <td>0.8087500000000001</td>\n",
    "   <td>0.6575</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">5</td>\n",
    "   <td align=\"center\">Gini</td>\n",
    "   <td>0.9106249999999999</td>\n",
    "   <td>0.64</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">Infinito</td>\n",
    "   <td align=\"center\">Gini</td>\n",
    "   <td>1.0</td>\n",
    "   <td>0.64</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">3</td>\n",
    "   <td align=\"center\">Entropía</td>\n",
    "   <td>0.796875</td>\n",
    "   <td>0.685</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">5</td>\n",
    "   <td align=\"center\">Entropía</td>\n",
    "   <td>0.89875</td>\n",
    "   <td>0.6525</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "   <td align=\"center\">Infinito</td>\n",
    "   <td align=\"center\">Entropía</td>\n",
    "   <td>1.0</td>\n",
    "   <td>0.66</td>\n",
    "   </tr>\n",
    "   </tbody></table>\n",
    "\n",
    "1. ¿Qué conclusiones se pueden sacar de estas tablas? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con los parametros {'criterion': 'gini', 'max_depth': 3} obtuvimos un train_accuracy=0.8087500000000001 y un validation_acurracy=0.6625\n",
      "Con los parametros {'criterion': 'gini', 'max_depth': 5} obtuvimos un train_accuracy=0.913125 y un validation_acurracy=0.635\n",
      "Con los parametros {'criterion': 'gini', 'max_depth': None} obtuvimos un train_accuracy=1.0 y un validation_acurracy=0.635\n",
      "Con los parametros {'criterion': 'entropy', 'max_depth': 3} obtuvimos un train_accuracy=0.796875 y un validation_acurracy=0.685\n",
      "Con los parametros {'criterion': 'entropy', 'max_depth': 5} obtuvimos un train_accuracy=0.89875 y un validation_acurracy=0.665\n",
      "Con los parametros {'criterion': 'entropy', 'max_depth': None} obtuvimos un train_accuracy=1.0 y un validation_acurracy=0.6425000000000001\n"
     ]
    }
   ],
   "source": [
    "param_grid={\"max_depth\":[3,5,None],\"criterion\":[\"gini\",\"entropy\"]}\n",
    "grid=list(ParameterGrid(param_grid))\n",
    "for param in grid:\n",
    "    tree_model=tree_model=DecisionTreeClassifier(**param)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores=cross_validate(\n",
    "    tree_model,\n",
    "    X_dev,\n",
    "    y_dev,\n",
    "    cv=skf,\n",
    "    scoring=\"accuracy\",\n",
    "    return_train_score=True\n",
    "    )\n",
    "    print(f\"Con los parametros {param} obtuvimos un train_accuracy={scores['train_score'].mean()} y un validation_acurracy={scores['test_score'].mean()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los modelos tienden a overfittear y que esto es mas evidente a medida que el arbol aumenta su profundidad en el caso de $depth=\\infty$ tenemos un accuracy 1 en el train y un accuracy mucho mas bajo en el test. Tambien pareceria no haber mucha diferencia entre los criterios de eleccion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "### Comparación de algoritmos \n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje con diferentes configuraciones con el objetivo de **encontrar el mejor modelo** de cada familia de buscar la performance óptima. Para este ejercicio realizar una experimentación utilizando [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Como métrica de performance usar AUCROC resultante de 5-fold cross-validation. \n",
    "\n",
    "Hiperparámetros_: Revisar la documentación de cada uno de los hiperparámetros para entender qué posibles hiperparámetros impacten de manera positiva en la construcción del algoritmo.\n",
    "\n",
    "Documentación extra sobre [`Tuning hyper-parameters`](https://scikit-learn.org/stable/modules/grid_search.html), leer hasta 3.2.2.\n",
    "\n",
    "1. Algoritmos a probar: \n",
    "  - Árboles de decisión. Mínimo 4 hiperparámetros.\n",
    "  - KNN (k-vecinos más cercanos). Mínimo 3 hiperparámetros.\n",
    "  - SVM (Support vector machine). Mínimo 2 hiperparámetros.\n",
    "\n",
    "Detallar los hiperparámetros elegidos para cada algoritmo y explicar la razón del espacio de búsqueda considerado para cada uno de estos, ¿cuántas iteraciones usaron?. A su vez, reportar la performance asociada de aquellos que consideren relevantes (al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "2. Compare los resultados obtenidos en el ejercicio anterior con los siguientes modelos con sus hiperparámetros default. \n",
    "\n",
    "  - LDA (Linear discriminant analysis)\n",
    "  - Naïve Bayes\n",
    "\n",
    "¿Qué resultados obtuvo? ¿Qué hiperparámetros podrían ser relevantes explorar en estos modelos? ¿Por qué?\n",
    "\n",
    "3. ¿Cuál fue el mejor modelo y con qué configuración? Explicar por qué creería que dio mejor (recordando qué hace cada algoritmo y con qué tipo de datos están trabajando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "### Comparación de algoritmos \n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje con diferentes configuraciones con el objetivo de **encontrar el mejor modelo** de cada familia de buscar la performance óptima. Para este ejercicio realizar una experimentación utilizando [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Como métrica de performance usar AUCROC resultante de 5-fold cross-validation. \n",
    "\n",
    "Hiperparámetros_: Revisar la documentación de cada uno de los hiperparámetros para entender qué posibles hiperparámetros impacten de manera positiva en la construcción del algoritmo.\n",
    "\n",
    "Documentación extra sobre [`Tuning hyper-parameters`](https://scikit-learn.org/stable/modules/grid_search.html), leer hasta 3.2.2.\n",
    "\n",
    "1. Algoritmos a probar: \n",
    "  - Árboles de decisión. Mínimo 4 hiperparámetros.\n",
    "  - KNN (k-vecinos más cercanos). Mínimo 3 hiperparámetros.\n",
    "  - SVM (Support vector machine). Mínimo 2 hiperparámetros.\n",
    "\n",
    "Detallar los hiperparámetros elegidos para cada algoritmo y explicar la razón del espacio de búsqueda considerado para cada uno de estos, ¿cuántas iteraciones usaron?. A su vez, reportar la performance asociada de aquellos que consideren relevantes (al menos la mejor combinación para cada algoritmo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero lo hacemos para arboles de decision, aca seguimos maso menos con la misma eleccion de hiperparametros de los ejercicios anteriores, probamos todas los criterios de seleccion para features y permitimos como maximo un depth de 10 para no overfittear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor configuracion de hiperparametros es: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 8, 'splitter': 'best'}\n",
      "El score promedio del mejor modelo es: 0.6371971861471861\n"
     ]
    }
   ],
   "source": [
    "#Primero lo hacemos para arboles de decision\n",
    "param_arboles={\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":randint(1,10),\n",
    "               'splitter': ['best', 'random'],\"min_samples_leaf\":randint(1,10)}\n",
    "n_iter=30\n",
    "k=5\n",
    "tree_model=DecisionTreeClassifier(random_state=42)\n",
    "random_search=RandomizedSearchCV(tree_model,param_distributions=param_arboles,n_iter=n_iter,cv=k,scoring=\"roc_auc\",\n",
    "                                 random_state=42)\n",
    "random_search.fit(X_dev,y_dev)\n",
    "mejor_modelo=random_search.best_estimator_\n",
    "print(f\"La mejor configuracion de hiperparametros es: {random_search.best_params_}\")\n",
    "print(f\"El score promedio del mejor modelo es: {random_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para K-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores hiperparametros son : {'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n",
      "El score promedio del mejor modelo es :0.8574021645021646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_knn={'n_neighbors': randint(3, 20),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2] }\n",
    "knn=KNeighborsClassifier()\n",
    "random_search=RandomizedSearchCV(knn,param_distributions=param_knn,n_iter=n_iter,cv=k,scoring=\"roc_auc\")\n",
    "random_search.fit(X_dev,y_dev)\n",
    "print(f\"Los mejores hiperparametros son : {random_search.best_params_}\")\n",
    "print(f\"El score promedio del mejor modelo es :{random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos con SVM, primero realizamos una estandarizacion de los datos debido a que en SVM se miden distancias (expandirse aca) luego probamos basicamente lo mas relevante para el modelo: el valor de C, aca lo que hicimos fue permitir que una proporcion razonable de los datos puedan estar en el lado incorrecto del margen, dado que tenemos del orden de 400 datos nos parecio prudente tomar como maximo C=50. Por otro lado, probamos kernels gaussianos, lineales y polinomicos, aca no hay mucho misterio; el mejor parametro esta asociado a la separacion de los datos, por ultimo la cantidad de iteraciones fue elegido para que el metodo converga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 25, 'svc__degree': 2, 'svc__kernel': 'poly', 'svc__max_iter': 11880}\n",
      "0.7936307359307359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Definimos el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "\n",
    "param_svm = [\n",
    "    {\n",
    "        \"svc__kernel\": [\"linear\"],\n",
    "        \"svc__C\": randint(10, 50),\n",
    "        \"svc__max_iter\": randint(10000, 20000)\n",
    "    },\n",
    "    {\n",
    "        \"svc__kernel\": [\"poly\"],\n",
    "        \"svc__C\": randint(10, 50),\n",
    "        \"svc__degree\": randint(1, 5),\n",
    "        \"svc__max_iter\": randint(10000, 20000)\n",
    "    },\n",
    "    {\n",
    "        \"svc__kernel\": [\"rbf\"],\n",
    "        \"svc__C\": randint(10, 50),\n",
    "        \"svc__max_iter\": randint(10000, 20000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Grid search\n",
    "grid_svm = RandomizedSearchCV(pipeline, param_distributions=param_svm,\n",
    "                              n_iter=n_iter, cv=k, scoring=\"roc_auc\")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_svm.fit(X_dev, y_dev)\n",
    "\n",
    "# Resultados\n",
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare los resultados obtenidos en el ejercicio anterior con los siguientes modelos con sus hiperparámetros default. \n",
    "\n",
    "  - LDA (Linear discriminant analysis)\n",
    "  - Naïve Bayes\n",
    "\n",
    "¿Qué resultados obtuvo? ¿Qué hiperparámetros podrían ser relevantes explorar en estos modelos? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para LDA seria relevante ver variantes del hiperparametro \"solver\" que por defecto utiliza una descomposicion SVD para no calcular la matriz de covarianza, otra opcion es \"lsqr\" o \"eigen\" que por lo que vimos es util cuando tenemos pocos datos (nuestro caso).\n",
    "El hiperparametro \"shrinkage\" podria ser util para evitar el overfitting, el default es None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score promedio del train del modelo LinearDiscriminantAnalysis() es 0.9956506717238927 y el score promedio del test es 0.724398593073593\n",
      "El score promedio del train del modelo GaussianNB() es 0.9698246007748195 y el score promedio del test es 0.7474482683982684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_nb=GaussianNB()\n",
    "lda=LinearDiscriminantAnalysis()\n",
    "modelos=[lda,gaussian_nb]\n",
    "skf = StratifiedKFold(\n",
    "            n_splits=5,\n",
    "            shuffle=True,\n",
    "            random_state=42)\n",
    "for model in modelos:\n",
    "    score = cross_validate(\n",
    "                model,   \n",
    "                X_dev,\n",
    "                y_dev,\n",
    "                cv=skf,\n",
    "                scoring='roc_auc',\n",
    "                return_train_score=True\n",
    "                )\n",
    "    print(f\"El score promedio del train del modelo {model} es {score['train_score'].mean()} y el score promedio del test es {score['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "### Diagnóstico Sesgo-Varianza.\n",
    "\n",
    "<span style=\"color: red;\">(no realizar hasta la clase _Sesgo y Varianza_)</span>\n",
    "\n",
    "En este punto, se pide inspeccionar **tres** de sus mejores modelos encontrados hasta ahora de cada familia de modelos: la mejor configuración para el árbol de decisión y la mejor configuración para SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo pero ahora incluya LDA. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo **RandomForest** con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos.\n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando AUC ROC como métrica para estas curvas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: \n",
    "### Evaluación de performance\n",
    "\n",
    "- La entrega del trabajo estará acompañada de una evaluación en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "- Su tarea será estimar la performance (AUCROC) que tendrá su mejor modelo en datos de evaluación (X_held_out). \n",
    "\n",
    "- Para ello, deberán predecir las **probabilidades** de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUCROC resultante y calcularemos el resultado real. Consideraremos que el **mejor modelo será el que se encuentre más cerca del valor real que calcularemos luego de la entrega**.\n",
    "\n",
    "- Recomendamos no perder de vista esta evaluación/competencia durante el desarrollo del TP, sobretodo en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "- Para que podamos evaluar la performance, junto con la entrega del informe, deberán enviar un archivo con el numero de grupo con dos digitos en formato csv con la columna `output` y el valor obtenido con 4 decimales (se subirá un ejemplo cuando se publiquen los datos de la competencia) y un valor esperado de AUCROC: `GG_y_pred_held_out_AUCROC`. \n",
    "\n",
    "    - Ej.: el grupo tres cree que obtuvo un valor de 0.7321 de AUCROC deberá submitear un archivo llamado: `03_y_pred_held_out_7321.csv`.\n",
    "\n",
    "- Los datos podrán encontrarlos en este [link](https://github.com/aprendizaje-automatico-dc-uba-ar/material/tree/main/tp/01_aprendizaje_supervisado/datos).\n",
    "\n",
    "- Las decisiones de este punto pueden desarrollarse hasta en una carilla, aunque con media debería alcanzar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6: \n",
    "### Conclusiones\n",
    "\n",
    "Escribir como mínimo en un párrafo, una conclusión del trabajo realizado, incluyendo problemas encontrados y \n",
    "aspectos no incluidos en el enunciado que hayan sido abordadas durante el desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entregables\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde podrán intercalar celdas para reportar y responder a los ítems de cada ejercicio. \n",
    "- Los entregrables serán\n",
    "    - Un informe en formato .pdf (**digital**) que responda a los ítems de este enunciado respetando la cantidad de espacio máximo por cada ítem. Nombrarlo siguiendo el formato `GG_Nombre_de_grupo`\n",
    "    - Adjuntar el notebook final en formatos .pdf e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (verificarlo haceindo: Kernel -> Restart and Run All). \n",
    "    - Las predicciones del *held out* del punto 5 en formato csv.\n",
    "- Habŕa una entrega intermedia obligatoria que deberán hacer antes del 17 de abril de 2025 a las 17:00hs. Para esta entrega deberán enviar el código que resuelve los primeros 3 ejercicios. \n",
    "- La **fecha** y **hora límite** de entrega está determinada en el campus de la materia.\n",
    "- El trabajo deberá elaborarse en grupos de 5 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importante: sobre el uso de ChatGPT y grandes modelos de lenguaje\n",
    "\n",
    "En este trabajo no estará explícitamente prohibido pero si fuertemente desaconsejado, consideramos a este trabajo práctico una importante herramienta de aprendizaje donde el uso de GPT puede ser perjudicial. En caso de usarlo se pide aclararlo en el informe y especificar cómo y en donde se utilizó. Así como expresar su opinión sobre la respuesta generada por el modelo pudiendo estar a favor o en contra de lo propuesto por este. Pueden adjuntar el link a la conversación con el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Agradecemos a [Martín García Sola](https://ar.linkedin.com/in/martin-e-garcia-sola) por la asistencia biológica en la confección de este Trabajo Práctico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
