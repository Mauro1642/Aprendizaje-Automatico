\documentclass[12pt,a4paper]{article}
% Packages
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}


% Page layout
\geometry{margin=1in}

% Title and author
\title{Informe de Aprendizaje Automático}
\author{Nombre del Estudiante \\ Universidad \\ Curso de Aprendizaje Automático}
\author{
    Chavez, Mauro \\
    \texttt{a@gmail.com}
    \and
    Lewkowicz, Iván \\
    \texttt{a@gmail.com}
    \and
    Drelewicz, Santiago \\
    \texttt{a@gmail.com}
    \and
    Torrez, Matías \\
    \texttt{matiastorrez157@gmail.com}
    \and
    Culaciati, Dante \\
    \texttt{a@gmail.com}
}


\date{\today}

% Custom settings for code listings
\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{gray!10},
    frame=single,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    breaklines=true,
    numbers=left,
    numberstyle=\tiny,
    stepnumber=1,
    numbersep=5pt
}

\begin{document}

% Title page
\maketitle
\newpage
\tableofcontents
\newpage

\section{Ejercicio 1}
\par En este inciso se pide separar los datos en conjuntos de entrenamiento y evaluación, donde no se debe utilizar la libreria \texttt{train\_test\_split} de \texttt{sklearn}.

\par Primero se realizo una exploracion de los datos, donde se observa que el dataset posee $200$ features, todas numericas, y $500$ filas.
Se observa que el dataset no tiene valores nulos y que ademas se trata de un problema desbalanceado, donde el $\%70$ de los datos pertenecen a la clase $1$ y el $\%$ restante pertenece a la clase $0$, por lo que no es necesario realizar un preprocesamiento de los datos. 
Se decide entonces utilizar el $80\%$ de los datos para entrenamiento y el $20\%$ restante para evaluacion.

\par Como la proporción de los datos es desbalanceada, realizamos un \texttt{stratified split} en la separación de los datos, procurando mantener la proporción del dataset original para los datos de entrenamiento y evaluación. 


\section{Ejercicio 2}
% Explique la fuente de los datos, su preprocesamiento y las características principales. Incluya gráficos si es necesario.
\par Para la primera parte de este ejercicio, entrenamos un arból de decisión con altura máxima 3 y estimamos la performance del modelo con K fold cross validation para distintas métricas. 
Las metricas utilizadas son \textit{Accuracy}, \textit{AUPRC} y \textit{AUC ROC} y se realizo un \textit{K-fold} con $K=5$.
\par En la tabla \ref{tab:resultados-permutaciones} se muestran los resultados obtenidos para cada una de las $5$ permutaciones de los datos, asi como el promedio de cada métrica para todas las permutaciones y el resultado global,
el cual se obtiene al calcular las metricas utilizando el conjuto de predicciones formado a partir de concatenar las predicciones de cada fold.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|P{2cm}|P{2.3cm}|P{1.8cm}|P{2.2cm}|P{2.1cm}|P{2cm}|}
    \hline
    \textbf{Permutación} & \textbf{Accuracy} (training) & \textbf{Accuracy} (validación) & \textbf{AUPRC} (training) & \textbf{AUPRC} (validación) & \textbf{AUCROC} (training) & \textbf{AUCROC} (validación) \\
    \hline
    1 & 0.8125   & 0.6375 & 0.6710 & 0.3226 & 0.8058 & 0.5298 \\
    \hline
    2 & 0.8406 & 0.5875 & 0.7337 & 0.3337 & 0.8458 & 0.5246 \\
    \hline
    3 & 0.825    & 0.6875 & 0.6431 & 0.3437 & 0.7513 & 0.5811 \\
    \hline
    4 & 0.8188  & 0.7    & 0.6573 & 0.3626 & 0.7877 & 0.5938 \\
    \hline
    5 & 0.8438  & 0.65   & 0.6958 & 0.4144 & 0.8085 & 0.5967 \\
    \hline  
    \textbf{Promedios} &  0.8281 & 0.6525 & 0.6802 & 0.3554 & 0.7998 & 0.5651 \\
    \hline
    \textbf{Global} & (NO) &  & (NO) &  & (NO) &  \\
    \hline
    \end{tabular}
\caption{Resultados por permutación y métricas}
\label{tab:resultados-permutaciones}
\end{table}


Se observa que este modelo presenta un buen desempeño en el conjunto de entrenamiento, pero su desempeño en el conjunto de validación es bastante bajo, lo que podría indicar que el modelo está sobreajustado a los datos de entrenamiento.

Para la segunda parte del ejercicio, se exploraron diferentes combinaciones de hiperparámetros para el modelo de árbol de decisión, utilizando \texttt{GridSearchCV} de \texttt{sklearn}.
 Se probaron diferentes valores para la profundidad máxima del árbol y el cirterio de corte. Se utilizó \texttt{StratifiedKFold} con $K=5$ para la validación cruzada.
En la tabla \ref{tab:resultados-arbol-gridsearch-1} se muestran los resultados obtenidos para cada combinación de hiperparámetros, así como el promedio de \textit{Accuracy} para cada combinación.
%no esta bien completa la tabla
 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Altura máxima} & \textbf{Criterio de corte} &\textbf{Accuracy} (training) &\textbf{Accuracy} (validación)  \\
    \hline
    3 & Gini   & 0.6375 & 0.6710  \\
    \hline
    5 & Gini & 0.5875 & 0.7337  \\
    \hline
    Infinito & Gini    & 0.6875 & 0.6431 \\
    \hline
    3 & Entropía & 0.7    & 0.6573  \\
    \hline
    5 & Entropía  & 0.65   & 0.6958  \\
    \hline  
    Infinito &  Entropía &  0.828125 &  0.828125 \\
    \hline
    \end{tabular}
    \caption{Resultados por permutación y métricas}
    \label{tab:resultados-arbol-gridsearch-1}
\end{table}

\section{Ejercicio 3}
\par En el tercer ejercicio compararemos distintas combinaciones de algoritmos, con diferentes configuraciones a fin de encontrar el mejor modelo para cada familia de algoritmo. La métrica a usar para evaluar estas combinaciones será AUCROC. Por otro lado, para estimar la performance utilizaremos Nested Cross Validation, ya que de esta forma no elegimos hiperparámetros y entrenamos sobre el mismo fold. En su lugar para cada modelo a evaluar, realizamos \textit{Stratified-CV} sobre nuestros datos, y a su vez realizamos en cada fold \textit{Stratified 4-Fold} nuevamente pero esta vez para probar distintos hiperparámetros. Luego elegimos los mejores hiper parámetros y evaluamos en un fold externo.

\subsection*{Árboles de decisión}
\par En nuestra búsqueda de hiperparámetros, tuvimos en cuenta las siguientes posibilidades:
\begin{itemize}
    \item Función de ganancia: Gini, Entropía
    \item Splitter: Best, Random
    \item Máxima Profundidad: Números aleatorios entre 1 y 20
    \item Cantidad mínima de ejemplares por división: Números aleatorios entre 1 y 20
    \item Cantidad mínima de ejemplares por hoja: Números aleatorios entre 1 y 20
    \item Pesos por clase: Ninguno, Balanceados
\end{itemize}
% Detallar elección de espacio de búsqueda
\par  Luego de realizar Nested CV con 500 iteraciones, encontramos que la mejor combinación de hiperparámetros es la siguiente
\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Hiperparámetro} & \textbf{Valor} \\
    \hline
    Class Weight & Balanced \\
    Criterion & Entropy \\
    Max Depth & 19 \\
    Min Samples Leaf & 16 \\
    Min Samples Split & 8 \\
    Splitter & Best \\
    \hline
    \textbf{ROC AUC Promedio} & 0.581 \\
    \textbf{Varianza} & 0.069 \\
    \textbf{ROC AUC Test} & 0.662 \\
    \hline
    \end{tabular}
    \caption{Mejores hiperparámetros encontrados para árboles de decisión.}
    \label{tab:mejores-hiperparametros-dtree}
\end{table}

% Deberíamos explicar qué rango de hiperparámetros exploramos y por qué

\subsection*{KNN} 
\par Para KNN encontramos que la mejor combinación de hiperparámetros es la siguiente

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Hiperparámetro} & \textbf{Valor} \\
    \hline
    Metric & Manhattan \\
    N-Neighbors & 9 \\
    P & 1 \\
    Weights & distance \\
    \hline
    \textbf{ROC AUC Promedio} & 0.859 \\
    \textbf{Varianza} & 0.063 \\
    \textbf{ROC AUC Test} & 0.836 \\
    \hline
    \end{tabular}
    \caption{Mejores hiperparámetros encontrados para KNN.}
    \label{tab:mejores-hiperparametros-knn}
\end{table}

\subsection*{Support Vector Machines}

\par Para SVM encontramos que la mejor combinación de hiperparámetros es la siguiente

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Hiperparámetro} & \textbf{Valor} \\
    \hline
    C & 141.9443 \\
    Class Weight & Ninguno \\
    Gamma & 0.0001655355812491995 \\
    Kernel & Radius Based Function \\
    \hline
    \textbf{ROC AUC Promedio} & 0.921 \\
    \textbf{Varianza} & 0.020 \\
    \textbf{ROC AUC Test} & 0.914 \\
    \hline
    \end{tabular}
    \caption{Mejores hiperparámetros encontrados para SVM.}
    \label{tab:mejores-hiperparametros-svm}
\end{table}


\section{Ejercicio 4}
Presente los resultados obtenidos, como métricas de evaluación, gráficos de desempeño, etc.

\section{Ejercicio 5}
Analice los resultados, las limitaciones del modelo y posibles mejoras.

\section{Conclusión}
Resuma los hallazgos principales y las conclusiones del informe.

\section*{Referencias}
Incluya las referencias bibliográficas utilizadas en el informe.

\end{document}