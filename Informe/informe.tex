\documentclass[12pt,a4paper]{article}
% Packages
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}

% Page layout
\geometry{margin=1in}

% Title and author
\title{Informe de Aprendizaje Automático}
\author{Nombre del Estudiante \\ Universidad \\ Curso de Aprendizaje Automático}
\author{
    Chavez, Mauro \\
    \texttt{a@gmail.com}
    \and
    Lewkowicz, Iván \\
    \texttt{a@gmail.com}
    \and
    Drelewicz, Santiago \\
    \texttt{a@gmail.com}
    \and
    Torrez, Matías \\
    \texttt{matiastorrez157@gmail.com}
    \and
    Culaciati, Dante \\
    \texttt{a@gmail.com}
}


\date{\today}

% Custom settings for code listings
\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{gray!10},
    frame=single,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    breaklines=true,
    numbers=left,
    numberstyle=\tiny,
    stepnumber=1,
    numbersep=5pt
}

\begin{document}

% Title page
\maketitle
\newpage
\tableofcontents
\newpage

\section{Ejercicio 1}
\par En este inciso se pide separar los datos en conjuntos de entrenamiento y evaluación, donde no se debe utilizar la libreria \texttt{train\_test\_split} de \texttt{sklearn}.

\par Primero se realizo una exploracion de los datos, donde se observa que el dataset posee $200$ features, todas numericas, y $500$ filas.
Se observa que el dataset no tiene valores nulos y que ademas se trata de un problema desbalanceado, donde el $\%70$ de los datos pertenecen a la clase $1$ y el $\%$ restante pertenece a la clase $0$, por lo que no es necesario realizar un preprocesamiento de los datos. 
Se decide entonces utilizar el $80\%$ de los datos para entrenamiento y el $20\%$ restante para evaluacion.

\par Como la proporción de los datos es desbalanceada, realizamos un \texttt{stratified split} en la separación de los datos, procurando mantener la proporción del dataset original para los datos de entrenamiento y evaluación. 

\section{Ejercicio 1.1}
\section{Ejercicio 2}
% Explique la fuente de los datos, su preprocesamiento y las características principales. Incluya gráficos si es necesario.
\par Para la primera parte de este ejercicio, entrenamos un arból de decisión con altura máxima 3 y estimamos la performance del modelo con K fold cross validation para distintas métricas. 
Las metricas utilizadas son \textit{Accuracy}, \textit{AUPRC} y \textit{AUC ROC} y se realizo un \textit{K-fold} con $K=5$.
\par En la tabla \ref{tab:resultados-permutaciones} se muestran los resultados obtenidos para cada una de las $5$ permutaciones de los datos, asi como el promedio de cada métrica para todas las permutaciones y el resultado global,
el cual se obtiene al calcular las metricas utilizando el conjuto de predicciones formado a partir de concatenar las predicciones de cada fold.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \textbf{Permutación} & \textbf{Accuracy} (training) & \textbf{Accuracy} (validación) & \textbf{AUPRC} (training) & \textbf{AUPRC} (validación) & \textbf{AUC ROC} (training) & \textbf{AUC ROC} (validación) \\
    \hline
    1 & 0.8125   & 0.6375 & 0.6710 & 0.3226 & 0.8058 & 0.5298 \\
    \hline
    2 & 0.840625 & 0.5875 & 0.7337 & 0.3337 & 0.8458 & 0.5246 \\
    \hline
    3 & 0.825    & 0.6875 & 0.6431 & 0.3437 & 0.7513 & 0.5811 \\
    \hline
    4 & 0.81875  & 0.7    & 0.6573 & 0.3626 & 0.7877 & 0.5938 \\
    \hline
    5 & 0.84375  & 0.65   & 0.6958 & 0.4144 & 0.8085 & 0.5967 \\
    \hline  
    \textbf{Promedios} &  0.828125 & 0.6525 & 0.6802 & 0.3554 & 0.7998 & 0.5651 \\
    \hline
    \textbf{Global} & (NO) &  & (NO) &  & (NO) &  \\
    \hline
    \end{tabular}
\caption{Resultados por permutación y métricas}
\label{tab:resultados-permutaciones}
\end{table}


Se observa que este modelo presenta un buen desempeño en el conjunto de entrenamiento, pero su desempeño en el conjunto de validación es bastante bajo, lo que podría indicar que el modelo está sobreajustado a los datos de entrenamiento.

Para la segunda parte del ejercicio, se exploraron diferentes combinaciones de hiperparámetros para el modelo de árbol de decisión, utilizando \texttt{GridSearchCV} de \texttt{sklearn}.
 Se probaron diferentes valores para la profundidad máxima del árbol y el cirterio de corte. Se utilizó \texttt{StratifiedKFold} con $K=5$ para la validación cruzada.
En la tabla \ref{tab:resultados-arbol-gridsearch-1} se muestran los resultados obtenidos para cada combinación de hiperparámetros, así como el promedio de \textit{Accuracy} para cada combinación.
%no esta bien completa la tabla
 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Altura máxima} & \textbf{Criterio de corte} &\textbf{Accuracy} (training) &\textbf{Accuracy} (validación)  \\
    \hline
    3 & Gini   & 0.6375 & 0.6710  \\
    \hline
    5 & Gini & 0.5875 & 0.7337  \\
    \hline
    Infinito & Gini    & 0.6875 & 0.6431 \\
    \hline
    3 & Entropía & 0.7    & 0.6573  \\
    \hline
    5 & Entropía  & 0.65   & 0.6958  \\
    \hline  
    Infinito &  Entropía &  0.828125 &  0.828125 \\
    \hline
    \end{tabular}
    \caption{Resultados por permutación y métricas}
    \label{tab:resultados-arbol-gridsearch-1}
\end{table}

\section{Ejercicio 3}
En esta seccion se exploraron diferentes combinaciones de hiperparametros para los modelos de arboles de decision, \textit{KNN} y \textit{SVM} y se los comparo contra los algoritmos \textit{LDA} y \textit{GaussianNB} sin realizar una busqueda de hiperparametros
. Se buscó identificar el mejor modelo de cada familia de algoritmos buscando maximizar el \textit{AUC ROC}.

Para realizar la busqueda de hiperparametros y la estimacion del rendimieinto de los modelos se utilizo la tecnica de \textit{Nested Cross Validation}, utilizando \textit{RondomizedSearchCV} para la busqueda de hiperparametros y, al igual que en la seccion anterior,
se utilizo \textit{StratifiedKFold} para la creacion de los \textit{Kfolds}.
\textit{Nested Cross Validation} es una técnica que permite evaluar el rendimiento de un modelo de aprendizaje automático mientras se optimizan sus hiperparámetros. En este enfoque, se utilizan dos bucles de validación cruzada: uno externo para evaluar el rendimiento del modelo y otro interno para ajustar los hiperparámetros. Esto ayuda a evitar el sobreajuste
 y proporciona una estimación más precisa del rendimiento del modelo en datos no vistos,~en la figura \ref{fig:nested_cross_validation} se muestra un esquema de como se realiza este proceso.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Imagenes/nested-kfold-cv.png}
    \caption{Esquema de \textit{Nested Cross Validation}, donde el bucle interno se utiliza para la búsqueda de hiperparámetros y el bucle externo para la evaluación del rendimiento.}
    \label{fig:nested_cross_validation}
\end{figure}

\subsection{Arbol de decisión}
A continuación se detallan los hiperparámetros utilizados junto con sus respectivos valores de prueba:

\begin{itemize}
    \item \texttt{max\_depth} (int o Ninguno): Altura máxima del árbol, mientras mas profundo sea el árbol, más complejo será el modelo y habra mas posibilidades de sobreajusta.
    \item \texttt{criterion} ({gini, entropia}): Criterio de corte,
    \item \texttt{splitter}: Estrategia de división, se probaron los valores \texttt{best} y \texttt{random}.
    \item \texttt{min\_samples\_leaf}: Cantidad mínima de muestras por hoja, se probaron los valores $1$, $2$ y $3$.
    \item \texttt{min\_samples\_split}: Cantidad mínima de muestras para dividir un nodo, se probaron los valores $2$, $3$ y $4$.
    \item \texttt{class\_weight}: Peso de las clases, se probaron los valores \texttt{balanced} y \texttt{None}.
\end{itemize}
\subsection{\textit{KNN}}

A continuación se detallan los hiperparámetros utilizados junto con sus respectivos valores de prueba:

\begin{itemize}
    \item \texttt{n\_neighbors}: Cantidad de vecinos a considerar, se probaron valores aleatorios en el rango de $3$ a $50$.
    \item \texttt{weights}: Estrategia de ponderación, se probaron los valores \texttt{uniform} y \texttt{distance}.
    \item \texttt{metric}: Métrica de distancia, se probaron las métricas \texttt{euclidean}, \texttt{manhattan}, \texttt{minkowski} y \texttt{cosine}.
    \item \texttt{p}: Potencia de la métrica de Minkowski, se probaron valores aleatorios entre $1$ y $4$.
    \item \texttt{algorithm}: Algoritmo de búsqueda de vecinos, se probaron los valores \texttt{auto}, \texttt{ball\_tree}, \texttt{kd\_tree} y \texttt{brute}.
\end{itemize}

\subsection{\textit{SVM}}

A continuación se detallan los hiperparámetros utilizados junto con sus respectivos valores de prueba:
\begin{itemize}
    \item \texttt{C}: Parámetro de regularización, se probaron valores aleatorios entre $0.1$ y $10$.
    \item \texttt{kernel}: Tipo de kernel a utilizar, se probaron los valores \texttt{linear}, \texttt{poly}, \texttt{rbf} y \texttt{sigmoid}.
    \item \texttt{degree}: Grado del polinomio, se probaron valores aleatorios entre $1$ y $5$.
    \item \texttt{gamma}: Coeficiente del kernel, se probaron valores aleatorios entre $0.01$ y $1$.
    \item \texttt{coef0}: Término independiente en el kernel, se probaron valores aleatorios entre $0$ y $1$.
\end{itemize}

\subsection{\textit{LDA} y \textit{GaussianNB}}

A pesar de que para comparar se utilizaron los algoritmos de \textit{LDA} y \textit{GaussianNB} sin realizar una búsqueda de hiperparámetros, se mencionan los posibles hiperparámetros
que podrían ser utilizados para estos algoritmos:
\begin{itemize}
    \item \textsl{LDA}:
    \begin{itemize}
        \item \texttt{solver}: Algoritmo de optimización, se pueden probar los valores \texttt{svd}, \texttt{lsqr} y \texttt{eigen}.
        \item \texttt{shrinkage}: Método de regularización, se pueden probar los valores \texttt{auto} y \texttt{None}.
        \item \texttt{tol}: Tolerancia para la convergencia, se pueden probar valores aleatorios entre $0.0001$ y $0.1$.
    \end{itemize}
    \item \textsl{GaussianNB}:
    \begin{itemize}
        \item \texttt{var\_smoothing}: Parámetro de suavizado de varianza, se pueden probar valores aleatorios entre $1e-9$ y $1e-1$.
    \end{itemize}
\end{itemize}

\subsection{Resultados}

 \section{Ejercicio 4}
Presente los resultados obtenidos, como métricas de evaluación, gráficos de desempeño, etc.

\section{Ejercicio 5}
Analice los resultados, las limitaciones del modelo y posibles mejoras.

\section{Conclusión}
Resuma los hallazgos principales y las conclusiones del informe.

\section*{Referencias}
Incluya las referencias bibliográficas utilizadas en el informe.

\end{document}